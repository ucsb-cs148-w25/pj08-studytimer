# Coding With AI Experiments
Documented below are our team members' individual AI coding experiments.

## Kevin
I used ChatGPT to help with scalability suggestions. Our project’s to-do list only stores user-inputted information on local storage with cookies. So over time or when cookies are cleared, all the tasks the user added to the to-do list would be removed. I had already set up Firebase for Google oAuth login but I needed help to scale Firebase to store user data from the web app. So Edwin and I gave the LLM the file containing the to-do list page, and it was able to figure out that we were using local storage. We did not know this because the page was developed by another teammate and there was no documentation on the storage. So the LLM suggested that we use Firebase’s Firestore as our database. Then I enabled Firestore on my Firebase Console and made the necessary changes to store user data from the to-do list. I only took the suggestion of a tool to use by the LLM and by reading documentation and seeing on the Firebase Console the user ID, I can tell that it worked correctly. Also when the user is logged out, all their data is no longer shown on the page. When they log back in, the data is seen again, therefore confirming that the database is working correctly. So ChatGPT’s recommendation of Firestore allowed us to scale our project with a working database.


## Andrew
My main task was implementing the UI and features of the HomePage. With the help of ChatGPT I was able to take my timer logic and effectively input it into our webapp. ChatGPT has also helped me figure out how to implement a variety of features like how to add sounds to our app, specifically for when the break timer starts and stops. I have also used ChatGPT to help me summarize the feedback we have received from other groups into notes that I can use to better our web app. With the help of AI, I am effectively able to take my ideas and learn how to merge my code with our app without the need to search the web endlessly to find tutorials that may not conform to my needs. Going forward I plan to implement a reward system for our app and will use the help of AI to devise the best way to set up such a system.


## Thienan
My task was to allow users to have multiple breaks within one study session. I used ChatGPT to help with the implementation of this. It suggested that when the user enters n breaks there will be n + 1 segments of study time. It suggested dividing the study session accordingly. I found ChatGPT to be very helpful in doing so. It ran into a few issues with ESlint and having missing dependencies but I was able to figure it out and fix it. ChatGPT was overall very helpful and smart in figuring out how to break up the study timer into multiple breaks even if there were a few hiccups.


## Lawrence
My main task was implementing the table UI of our “To-Do” List page, and I used ChatGPT to help with the CSS formatting of the page to match with the home and other pages of our website. For this implementation since we had not set up the backend with Firestore yet, I wanted to find a way to save the information locally per session i.e. local host. ChatGPT helped set up the logic for preserving the data throughout the user’s session. It was also very helpful in setting up the logic of moving tasks back and forth from “In Progress” to “Done”, which later helped create a foundation for setting the backend code with Firestore. There were some problems when implementing the libraries I wanted i.e. drag&drop, so for that portion I mainly used the documentation one of our team members provided to help implement the feature to drag tasks to their respective order within a table. Overall, ChatGPT’s suggestions allowed the frontend design of the page to be user friendly, as noted in our MVP feedback  


## Jennifer
I used ChatGPT to help me write unit tests for one of our files in frontend components, Login.js. I chose to write unit tests for this file since ensuring that our users can log in properly through Google OAuth is considered a top priority for our team. I had implemented unit tests in the past but I was not entirely sure how to approach writing the tests for this file. ChatGPT helped guide me through the process and suggested how to mock and render the components in our Login.js file. I did go down a rabbit hole because some of its suggestions for fixing the tests, which were not working, were a bit misleading. Regardless, ChatGPT it was pretty helpful overall and I was able to implement the unit tests. Moving forward, I think that using ChatGPT for guidance on writing more unit tests will be beneficial for our team's best interest. 


## Edwin
My task for the week was to improve our “To Do” page on our web app, per the feedback that we received during the MVP. The main feedback recommended the page spend more time on the tasks, and the metrics/assessments of the user’s productivity could be moved elsewhere so that the page is solely the start of your productivity! For that, I used Figma to design what I will call the “Task Board”, and it essentially just looks like a Kanban board but is more oriented to handling tasks rather than PRs and issues. Once I had settled on the design, I decided to see IF v0 could create a functional page, with just the image itself and some brief description of the previous “To Do” page. Sadly, the results/product that was delivered didn’t meet my expectations functionally, but aesthetically it got it nearly there and even created new components that I thought were interesting! So while I won’t be using any of the code that was given as it doesn’t necessarily integrate with the project well, I have a lot of new ideas that I would like to figure out and implement for the revamped/improved page.


## Cindy
I summarized the feedback we got from the MVP using three LLMs: ChatGPT, Claude, and DeepSeek. I completed a zero-shot query for ChatGPT by copying and pasting the MVP suggestions and asking it to summarize the text without additional context. It distinguished the feedback by two sections, Requested Features and UI/UX Improvements, which was a helpful distinction towards organizing the MVP feedback. It also suggested some business strategies to competitively differentiate our app from existing apps, such as clarifying in our demo what sets our app apart from existing/built-in productivity apps such as Apple Timer and Google Calendar. For Claude, I prompted it to summarize the MVP suggestions into the 3 most popular new features and 3 most popular changes to existing features. It performed well by grouping the suggestions by adding new features or updating/changing existing features. It suggested that we add a metrics page, integrate the calendar, and add social functionality, which were good suggestions corroborating our plan for the app. Finally, I used DeepSeek with the same query as Claude to see if it would produce similar results. Claude and DeepSeek grouped the features differently, but verified each other for the most part. DeepSeek also suggested some “honorable mention” features not as frequently stated as the top 3 but worth implementing. Overall, I used various LLMs to summarize the feedback from our peers and generate documentation and business strategies going forward. I believe this tool is helpful for summarizing large amounts of customer feedback and users can verify AI results using other AI models.
